import os
import logging
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from typing import List, Dict, Tuple, Optional
import sqlite3
import json
from datetime import datetime
import pickle

from services.training_data_service import get_training_service
from services.unified_database_search import UnifiedDatabaseService

logger = logging.getLogger(__name__)

class TrainingDataset(Dataset):
    """Dataset –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤"""
    
    def __init__(self, examples: List[Dict], preprocess, device):
        self.examples = examples
        self.preprocess = preprocess
        self.device = device
        
    def __len__(self):
        return len(self.examples)
    
    def __getitem__(self, idx):
        example = self.examples[idx]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_path = example['image_path']
        if not os.path.exists(image_path):
            # Fallback - —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.new('RGB', (224, 224), color=(128, 128, 128))
        else:
            image = Image.open(image_path)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image_tensor = self.preprocess(image)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫—É (1 –¥–ª—è correct, 0 –¥–ª—è incorrect)
        label = 1 if example['feedback_type'] == 'correct' else 0
        
        return {
            'image': image_tensor,
            'label': torch.tensor(label, dtype=torch.float32),
            'similarity_score': torch.tensor(example.get('similarity_score', 0.5), dtype=torch.float32),
            'quality_rating': torch.tensor(example.get('quality_rating', 5), dtype=torch.float32)
        }

class ModelTrainingService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.training_service = get_training_service()
        self.unified_service = UnifiedDatabaseService()
        self.model = None
        self.preprocess = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        self.learning_rate = 1e-5
        self.batch_size = 8
        self.num_epochs = 3
        self.weight_decay = 0.01
        
        logger.info(f"üöÄ ModelTrainingService –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ {self.device}")
    
    def _load_clip_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ CLIP –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            try:
                import clip
                self.model, self.preprocess = clip.load("ViT-B/32", device=self.device)
                logger.info("‚úÖ CLIP –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CLIP –º–æ–¥–µ–ª–∏: {e}")
                raise
    
    def prepare_training_data(self, min_examples: int = 10) -> Tuple[List[Dict], List[Dict]]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            min_examples: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            Tuple[train_data, validation_data]
        """
        # –ü–æ–ª—É—á–∞–µ–º –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        all_examples = self.training_service.get_training_examples(is_used=False)
        
        if len(all_examples) < min_examples:
            logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(all_examples)} < {min_examples}")
            return [], []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        valid_examples = []
        for example in all_examples:
            if example['image_path'] and os.path.exists(example['image_path']):
                valid_examples.append(example)
        
        logger.info(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(valid_examples)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏ (80/20)
        train_size = int(0.8 * len(valid_examples))
        train_data = valid_examples[:train_size]
        val_data = valid_examples[train_size:]
        
        return train_data, val_data
    
    def create_contrastive_pairs(self, examples: List[Dict]) -> List[Dict]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            examples: –°–ø–∏—Å–æ–∫ –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –º–µ—Ç–∫–∞–º–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏
        """
        pairs = []
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ —Ç–∏–ø—É –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        correct_examples = [ex for ex in examples if ex['feedback_type'] == 'correct']
        incorrect_examples = [ex for ex in examples if ex['feedback_type'] == 'incorrect']
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)
        for i, example1 in enumerate(correct_examples):
            for j, example2 in enumerate(correct_examples[i+1:], i+1):
                if example1['target_item_id'] == example2['target_item_id']:
                    pairs.append({
                        'image1_path': example1['image_path'],
                        'image2_path': example2['image_path'],
                        'label': 1,  # –ü–æ—Ö–æ–∂–∏–µ
                        'similarity_score': min(example1.get('similarity_score', 0.5),
                                              example2.get('similarity_score', 0.5))
                    })
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä—ã (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π + –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π)
        for correct_ex in correct_examples:
            for incorrect_ex in incorrect_examples:
                pairs.append({
                    'image1_path': correct_ex['image_path'],
                    'image2_path': incorrect_ex['image_path'],
                    'label': 0,  # –ù–µ –ø–æ—Ö–æ–∂–∏–µ
                    'similarity_score': 0.1
                })
        
        logger.info(f"üìù –°–æ–∑–¥–∞–Ω–æ {len(pairs)} –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return pairs
    
    def fine_tune_model(self, train_data: List[Dict], val_data: List[Dict] = None,
                       model_version: str = None) -> Dict:
        """
        –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        
        Args:
            train_data: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            val_data: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            model_version: –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        """
        if not model_version:
            model_version = f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        start_time = time.time()
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            self._load_clip_model()
            
            # –°–æ–∑–¥–∞–µ–º datasets
            train_dataset = TrainingDataset(train_data, self.preprocess, self.device)
            train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)
            
            val_loader = None
            if val_data:
                val_dataset = TrainingDataset(val_data, self.preprocess, self.device)
                val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
            optimizer = optim.AdamW(self.model.parameters(), 
                                  lr=self.learning_rate, 
                                  weight_decay=self.weight_decay)
            
            # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
            criterion = nn.BCEWithLogitsLoss()
            
            # –û–±—É—á–µ–Ω–∏–µ
            train_losses = []
            val_accuracies = []
            
            accuracy_before = self._evaluate_model(val_loader) if val_loader else None
            
            for epoch in range(self.num_epochs):
                # –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è —ç–ø–æ—Ö–∞
                self.model.train()
                epoch_loss = 0.0
                
                for batch in train_loader:
                    optimizer.zero_grad()
                    
                    images = batch['image'].to(self.device)
                    labels = batch['label'].to(self.device)
                    
                    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    with torch.cuda.amp.autocast() if self.device == "cuda" else torch.no_grad():
                        image_features = self.model.encode_image(images)
                        
                        # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        predictions = torch.sigmoid(torch.sum(image_features, dim=1))
                    
                    loss = criterion(predictions, labels)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                
                avg_loss = epoch_loss / len(train_loader)
                train_losses.append(avg_loss)
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è
                if val_loader:
                    val_accuracy = self._evaluate_model(val_loader)
                    val_accuracies.append(val_accuracy)
                    logger.info(f"–≠–ø–æ—Ö–∞ {epoch+1}/{self.num_epochs}: Loss={avg_loss:.4f}, Val_Acc={val_accuracy:.4f}")
                else:
                    logger.info(f"–≠–ø–æ—Ö–∞ {epoch+1}/{self.num_epochs}: Loss={avg_loss:.4f}")
            
            accuracy_after = self._evaluate_model(val_loader) if val_loader else None
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            model_path = self._save_model(model_version)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            duration = int(time.time() - start_time)
            positive_examples = len([ex for ex in train_data if ex['feedback_type'] == 'correct'])
            negative_examples = len([ex for ex in train_data if ex['feedback_type'] == 'incorrect'])
            
            training_params = {
                'learning_rate': self.learning_rate,
                'batch_size': self.batch_size,
                'num_epochs': self.num_epochs,
                'weight_decay': self.weight_decay,
                'train_losses': train_losses,
                'val_accuracies': val_accuracies
            }
            
            session_id = self.training_service.log_training_session(
                model_version=model_version,
                examples_count=len(train_data),
                positive_count=positive_examples,
                negative_count=negative_examples,
                accuracy_before=accuracy_before,
                accuracy_after=accuracy_after,
                duration_seconds=duration,
                parameters=training_params,
                notes=f"Fine-tuned CLIP model on user feedback"
            )
            
            # –û—Ç–º–µ—á–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ
            example_ids = [ex['id'] for ex in train_data]
            self.training_service.mark_examples_as_used(example_ids)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î
            self._update_product_vectors(model_version)
            
            logger.info(f"‚úÖ –î–æ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å: {model_version}, –°–µ—Å—Å–∏—è: {session_id}")
            
            return {
                'success': True,
                'model_version': model_version,
                'session_id': session_id,
                'examples_used': len(train_data),
                'accuracy_before': accuracy_before,
                'accuracy_after': accuracy_after,
                'training_duration': duration,
                'model_path': model_path
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return {
                'success': False,
                'error': str(e),
                'model_version': model_version
            }
    
    def _evaluate_model(self, data_loader) -> float:
        """–û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏"""
        if not data_loader:
            return 0.0
        
        self.model.eval()
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in data_loader:
                images = batch['image'].to(self.device)
                labels = batch['label'].to(self.device)
                
                image_features = self.model.encode_image(images)
                predictions = torch.sigmoid(torch.sum(image_features, dim=1))
                predicted_labels = (predictions > 0.5).float()
                
                total += labels.size(0)
                correct += (predicted_labels == labels).sum().item()
        
        return correct / total if total > 0 else 0.0
    
    def _save_model(self, model_version: str) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        try:
            models_dir = 'models/fine_tuned'
            os.makedirs(models_dir, exist_ok=True)
            
            model_path = os.path.join(models_dir, f'clip_finetuned_{model_version}.pt')
            
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'version': model_version,
                'timestamp': datetime.now().isoformat(),
                'device': self.device
            }, model_path)
            
            logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            return model_path
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
            return ""
    
    def _update_product_vectors(self, model_version: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é"""
        try:
            logger.info("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é...")
            
            # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è, –ø–æ—ç—Ç–æ–º—É –∑–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–µ
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ unified_products.db
            # —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            
            # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            logger.info(f"‚úÖ –í–µ–∫—Ç–æ—Ä—ã —Ç–æ–≤–∞—Ä–æ–≤ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–∏ {model_version}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤: {e}")
    
    def auto_training_check(self) -> bool:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è
        
        Returns:
            True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–æ–æ–±—É—á–µ–Ω–∏–µ
        """
        try:
            stats = self.training_service.get_training_statistics()
            
            # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è
            unused_examples = stats.get('unused_examples', 0)
            min_examples_threshold = 50
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
            if unused_examples >= min_examples_threshold:
                logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {unused_examples} –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–æ–±—É—á–µ–Ω–∏–µ")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def get_training_recommendations(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –¥–æ–æ–±—É—á–µ–Ω–∏—é"""
        try:
            stats = self.training_service.get_training_statistics()
            
            recommendations = {
                'should_train': False,
                'reasons': [],
                'stats': stats
            }
            
            unused_examples = stats.get('unused_examples', 0)
            
            if unused_examples >= 50:
                recommendations['should_train'] = True
                recommendations['reasons'].append(f"–ù–∞–∫–æ–ø–ª–µ–Ω–æ {unused_examples} –Ω–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
            
            if unused_examples >= 20:
                recommendations['reasons'].append("–î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –¥–æ–æ–±—É—á–µ–Ω–∏—è")
            
            # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–º–µ—Ä–æ–≤
            feedback_types = stats.get('by_feedback_type', {})
            correct_count = feedback_types.get('correct', 0)
            incorrect_count = feedback_types.get('incorrect', 0)
            
            if correct_count > 0 and incorrect_count > 0:
                recommendations['reasons'].append("–ï—Å—Ç—å –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ, —Ç–∞–∫ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return {'should_train': False, 'reasons': [], 'error': str(e)}
    
    def create_model_backup(self, model_version: str = None) -> Dict:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
        
        Args:
            model_version: –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        """
        try:
            if not model_version:
                model_version = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            backups_dir = 'models/backups'
            os.makedirs(backups_dir, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
            backup_path = os.path.join(backups_dir, f'clip_backup_{model_version}.pt')
            
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'version': model_version,
                'timestamp': datetime.now().isoformat(),
                'device': self.device,
                'backup_type': 'manual',
                'original_model': 'clip-vit-base-patch32'
            }, backup_path)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            metadata = {
                'backup_id': model_version,
                'created_at': datetime.now().isoformat(),
                'model_path': backup_path,
                'file_size': os.path.getsize(backup_path) if os.path.exists(backup_path) else 0,
                'backup_type': 'manual'
            }
            
            self.training_service.log_model_backup(metadata)
            
            logger.info(f"üíæ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            
            return {
                'success': True,
                'backup_id': model_version,
                'path': backup_path,
                'size': metadata['file_size'],
                'created_at': metadata['created_at']
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def restore_model_from_backup(self, backup_id: str) -> Dict:
        """
        –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
        
        Args:
            backup_id: ID —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        try:
            backup_path = f'models/backups/clip_backup_{backup_id}.pt'
            
            if not os.path.exists(backup_path):
                return {
                    'success': False,
                    'error': f'–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è {backup_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
                }
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
            current_backup = self.create_model_backup(f"before_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            checkpoint = torch.load(backup_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {backup_id}")
            
            return {
                'success': True,
                'backup_id': backup_id,
                'restored_at': datetime.now().isoformat(),
                'current_backup': current_backup
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def list_model_backups(self) -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        try:
            backups = []
            backups_dir = 'models/backups'
            
            if not os.path.exists(backups_dir):
                return backups
            
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª—ã —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
            for filename in os.listdir(backups_dir):
                if filename.startswith('clip_backup_') and filename.endswith('.pt'):
                    backup_path = os.path.join(backups_dir, filename)
                    backup_id = filename.replace('clip_backup_', '').replace('.pt', '')
                    
                    try:
                        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
                        checkpoint = torch.load(backup_path, map_location='cpu')
                        
                        backup_info = {
                            'backup_id': backup_id,
                            'file_path': backup_path,
                            'file_size': os.path.getsize(backup_path),
                            'created_at': checkpoint.get('timestamp', 'Unknown'),
                            'version': checkpoint.get('version', backup_id),
                            'backup_type': checkpoint.get('backup_type', 'unknown'),
                            'model_type': checkpoint.get('original_model', 'CLIP')
                        }
                        
                        backups.append(backup_info)
                        
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ {filename}: {e}")
                        # –î–æ–±–∞–≤–ª—è–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                        backups.append({
                            'backup_id': backup_id,
                            'file_path': backup_path,
                            'file_size': os.path.getsize(backup_path),
                            'created_at': 'Unknown',
                            'version': backup_id,
                            'backup_type': 'unknown',
                            'model_type': 'CLIP'
                        })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            backups.sort(key=lambda x: x.get('created_at', ''), reverse=True)
            
            return backups
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: {e}")
            return []
    
    def cleanup_old_backups(self, keep_count: int = 10) -> Dict:
        """
        –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π
        
        Args:
            keep_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—á–∏—Å—Ç–∫–∏
        """
        try:
            backups = self.list_model_backups()
            
            if len(backups) <= keep_count:
                return {
                    'success': True,
                    'deleted_count': 0,
                    'kept_count': len(backups),
                    'message': '–û—á–∏—Å—Ç–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è'
                }
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–ø–∏–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º keep_count –Ω–æ–≤—ã—Ö)
            to_delete = backups[keep_count:]
            deleted_count = 0
            
            for backup in to_delete:
                try:
                    if os.path.exists(backup['file_path']):
                        os.remove(backup['file_path'])
                        deleted_count += 1
                        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup['backup_id']}")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é {backup['backup_id']}: {e}")
            
            return {
                'success': True,
                'deleted_count': deleted_count,
                'kept_count': len(backups) - deleted_count,
                'message': f'–£–¥–∞–ª–µ–Ω–æ {deleted_count} —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π'
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π: {e}")
            return {
                'success': False,
                'error': str(e)
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
_model_training_service = None

def get_model_training_service() -> ModelTrainingService:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å–µ—Ä–≤–∏—Å–∞ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    global _model_training_service
    if _model_training_service is None:
        _model_training_service = ModelTrainingService()
    return _model_training_service 