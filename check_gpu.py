#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ GPU –∏ CUDA
"""

import torch
import sys

def check_gpu_availability():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –∏ CUDA"""
    
    print("üîç –ü–†–û–í–ï–†–ö–ê GPU –ò CUDA")
    print("="*50)
    
    # –í–µ—Ä—Å–∏—è PyTorch
    print(f"üì¶ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA
    cuda_available = torch.cuda.is_available()
    print(f"‚ö° CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {'‚úÖ –î–∞' if cuda_available else '‚ùå –ù–µ—Ç'}")
    
    if cuda_available:
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
        gpu_count = torch.cuda.device_count()
        print(f"üéÆ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {gpu_count}")
        
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024**3)
            print(f"  GPU {i}: {gpu_name} ({gpu_memory:.2f} –ì–ë)")
        
        current_device = torch.cuda.current_device()
        print(f"üéØ –¢–µ–∫—É—â–µ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: GPU {current_device}")
        
        # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ –Ω–∞ GPU
        try:
            test_tensor = torch.rand(10, 10).cuda()
            print("‚úÖ –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ –Ω–∞ GPU: —É—Å–ø–µ—à–Ω–æ")
            del test_tensor
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–µ–Ω–∑–æ—Ä–∞ –Ω–∞ GPU: {e}")
    else:
        print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        
        # –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è CUDA
        print("\nüîß –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è CUDA:")
        print("1. –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA")
        print("2. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ CPU-–≤–µ—Ä—Å–∏—è PyTorch")
        print("3. –í–µ—Ä—Å–∏—è CUDA –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å PyTorch")
        print("4. –ù–µ—Ç NVIDIA GPU –Ω–∞ —ç—Ç–æ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ")

def check_nvidia_gpu():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ NVIDIA GPU –≤ —Å–∏—Å—Ç–µ–º–µ"""
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("\nüéÆ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û GPU –ò–ó nvidia-smi:")
            print("-" * 50)
            lines = result.stdout.split('\n')
            for line in lines:
                if 'GeForce' in line or 'RTX' in line or 'GTX' in line or 'Tesla' in line:
                    print(f"  {line.strip()}")
            return True
        else:
            print("\n‚ùå nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–¥—Ä–∞–π–≤–µ—Ä—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–ª–∏ –Ω–µ—Ç NVIDIA GPU)")
            return False
    except FileNotFoundError:
        print("\n‚ùå nvidia-smi –Ω–µ –Ω–∞–π–¥–µ–Ω (–¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã)")
        return False
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ nvidia-smi: {e}")
        return False

def suggest_cuda_installation():
    """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–ø–æ—Å–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ CUDA –≤–µ—Ä—Å–∏–∏ PyTorch"""
    
    print("\nüõ†Ô∏è –ö–ê–ö –£–°–¢–ê–ù–û–í–ò–¢–¨ CUDA –í–ï–†–°–ò–Æ PYTORCH:")
    print("="*50)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é CUDA –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞
    if torch.cuda.is_available():
        cuda_version = torch.version.cuda
        print(f"üì¶ –í–µ—Ä—Å–∏—è CUDA –≤ PyTorch: {cuda_version}")
    
    print("\n1Ô∏è‚É£ –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:")
    print("   pip uninstall torch torchvision torchaudio")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    
    print("\n2Ô∏è‚É£ –ò–ª–∏ –¥–ª—è CUDA 12.1:")
    print("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    
    print("\n3Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:")
    print("   - –°–∞–π—Ç: https://pytorch.org/get-started/locally/")
    print("   - –í—ã–±–µ—Ä–∏—Ç–µ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é CUDA")
    
    print("\n4Ô∏è‚É£ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä—ã NVIDIA (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ):")
    print("   - https://www.nvidia.com/Download/index.aspx")

if __name__ == "__main__":
    check_gpu_availability()
    
    has_nvidia = check_nvidia_gpu()
    
    if not torch.cuda.is_available() and has_nvidia:
        suggest_cuda_installation()
    elif not torch.cuda.is_available() and not has_nvidia:
        print("\nüí° –í —ç—Ç–æ–π —Å–∏—Å—Ç–µ–º–µ –Ω–µ—Ç NVIDIA GPU. GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ.")
        print("   –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞ CPU (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ).") 